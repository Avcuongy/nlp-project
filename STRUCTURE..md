# Cáº¥u TrÃºc Dá»± Ãn NLP - PhÃ¢n Loáº¡i Cáº£m XÃºc Tiáº¿ng Viá»‡t

## ÄÃ¡nh GiÃ¡ Cáº¥u TrÃºc

### Æ¯u Ä‘iá»ƒm:
1. **PhÃ¢n tÃ¡ch rÃµ rÃ ng** giá»¯a code thá»­ nghiá»‡m (notebooks) vÃ  production code (src)
2. **Quáº£n lÃ½ config tá»‘t** vá»›i file riÃªng cho tá»«ng thuáº­t toÃ¡n ML/DL
3. **Data pipeline chuáº©n**: raw â†’ processed â†’ external
4. **ÄÃ¡nh sá»‘ notebooks** theo workflow nghiÃªn cá»©u
5. **LÆ°u trá»¯ artifacts** phÃ¢n biá»‡t ML (Pickle) vÃ  DL (PyTorch)

### Cáº£i tiáº¿n Ä‘á» xuáº¥t:
- TÃ¡ch `app/` ra ngoÃ i cÃ¹ng cáº¥p vá»›i `src/` (khÃ´ng náº±m trong src)
- ThÃªm `scripts/` cho cÃ¡c file cháº¡y Ä‘á»™c láº­p (train_all.py, evaluate_all.py)
- Gá»™p `features/` vÃ o `preprocessing/` (vectorizer lÃ  bÆ°á»›c tiá»n xá»­ lÃ½)
- ThÃªm `Dockerfile`, `.dockerignore` cho deployment
- ThÃªm `.env.example` cho biáº¿n mÃ´i trÆ°á»ng

---

## Cáº¥u TrÃºc ÄÆ°á»£c Tá»‘i Æ¯u HÃ³a

```
nlp-prj-group-08/
â”‚
â”œâ”€â”€ .gitignore                  # Loáº¡i bá»: data/, models/, .env, __pycache__
â”œâ”€â”€ .dockerignore               # Loáº¡i bá»: notebooks/, .git, *.ipynb
â”œâ”€â”€ .env.example                # Template cho biáº¿n mÃ´i trÆ°á»ng (API keys, paths)
â”œâ”€â”€ Dockerfile                  # Container hÃ³a á»©ng dá»¥ng
â”œâ”€â”€ docker-compose.yml          # (TÃ¹y chá»n) Cháº¡y multi-service (app + database)
â”‚
â”œâ”€â”€ README.md                   # HÆ°á»›ng dáº«n cÃ i Ä‘áº·t & reproduce káº¿t quáº£
â”œâ”€â”€ requirements.txt            # Dependencies: scikit-learn, torch, transformers, underthesea
â”œâ”€â”€ setup.py                    # CÃ i Ä‘áº·t package: pip install -e .
â”‚
â”œâ”€â”€ config/                     # Quáº£n lÃ½ cáº¥u hÃ¬nh táº­p trung
â”‚   â”œâ”€â”€ config.yaml             # File config chung (paths, random_seed, train/test split)
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ a.yaml              # Naive Bayes: alpha, fit_prior
â”‚   â”‚   â”œâ”€â”€ b.yaml              # Logistic Regression: C, penalty, solver
â”‚   â”‚   â””â”€â”€ c.yaml              # SVM: C, kernel, gamma
â”‚   â””â”€â”€ dl/
â”‚       â””â”€â”€ UNGTHU.yaml         # PhoBERT: lr, batch_size, epochs, max_len, warmup_steps
â”‚
â”œâ”€â”€ data/                       # Quáº£n lÃ½ dá»¯ liá»‡u (KHÃ”NG COMMIT LÃŠN GIT)
â”‚   â”œâ”€â”€ raw/                    # Dá»¯ liá»‡u gá»‘c (READ-ONLY)
â”‚   â”‚   â”œâ”€â”€ VLSP.xml
â”‚   â”‚   â””â”€â”€ Foody.csv
â”‚   â”œâ”€â”€ processed/              # Dá»¯ liá»‡u sau tiá»n xá»­ lÃ½
â”‚   â”‚   â”œâ”€â”€ train.csv           # Gá»“m: text, label
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â””â”€â”€ val.csv             # (TÃ¹y chá»n) Validation set
â”‚   â””â”€â”€ external/               # TÃ i nguyÃªn bÃªn ngoÃ i
â”‚       â”œâ”€â”€ vietnamese-stopwords.txt
â”‚       â”œâ”€â”€ teencode_dict.json  # Tá»« Ä‘iá»ƒn chuyá»ƒn teencode â†’ tiáº¿ng Viá»‡t chuáº©n
â”‚       â””â”€â”€ emojis_sentiment.json
â”‚
â”œâ”€â”€ models/                     # Model artifacts (KHÃ”NG COMMIT)
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ naive_bayes.pkl
â”‚   â”‚   â”œâ”€â”€ logistic_regression.pkl
â”‚   â”‚   â”œâ”€â”€ svm.pkl
â”‚   â”‚   â””â”€â”€ tfidf_vectorizer.pkl  # Pháº£i lÆ°u vectorizer Ä‘á»ƒ inference
â”‚   â””â”€â”€ dl/
â”‚       â”œâ”€â”€ phobert_best.bin      # Checkpoint tá»‘t nháº¥t
â”‚       â”œâ”€â”€ training_args.json    # Log hyperparameters Ä‘Ã£ dÃ¹ng
â”‚       â””â”€â”€ tokenizer/            # Custom tokenizer (náº¿u thÃªm tá»« vá»±ng)
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks (Research & EDA)
â”‚   â”œâ”€â”€ analysis/               # PhÃ¢n tÃ­ch dá»¯ liá»‡u
â”‚   â”‚   â”œâ”€â”€ 1_clean.ipynb       # EDA: phÃ¢n bá»‘ nhÃ£n, Ä‘á»™ dÃ i text, missing values
â”‚   â”‚   â”œâ”€â”€ 2_tokenize.ipynb    # Thá»­ nghiá»‡m lÃ m sáº¡ch: regex, teencode, emoji
â”‚   â”‚   â””â”€â”€ 3_vectorize.ipynb   # So sÃ¡nh TF-IDF vs Word2Vec vs FastText
â”‚   â””â”€â”€ model/                  # Thá»­ nghiá»‡m mÃ´ hÃ¬nh
â”‚       â”œâ”€â”€ a.ipynb             # Cháº¡y & tune 3 mÃ´ hÃ¬nh ML
â”‚       â”œâ”€â”€ b.ipynb             # Cháº¡y & tune 3 mÃ´ hÃ¬nh ML
â”‚       â”œâ”€â”€ c.ipynb             # Cháº¡y & tune 3 mÃ´ hÃ¬nh ML
â”‚       â””â”€â”€ UNGTHU.ipynb        # Fine-tune PhoBERT trÃªn GPU
â”‚
â”œâ”€â”€ src/                        # Production Code (Clean & Modular)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/          # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ clean.py            # LÃ m sáº¡ch: lowercase, remove URL/emoji, normalize unicode
â”‚   â”‚   â”œâ”€â”€ tokenize.py         # TÃ¡ch tá»«: underthesea.word_tokenize, NLTK
â”‚   â”‚   â”œâ”€â”€ vectorizer.py       # TF-IDF, CountVectorizer, N-grams
â”‚   â”‚   â””â”€â”€ augmentation.py     # (NÃ¢ng cao) Back-translation, synonym replacement
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # Äá»‹nh nghÄ©a & lÆ°u mÃ´ hÃ¬nh
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ml_models.py        # Class wrapper cho NB, LR, SVM
â”‚   â”‚   â”œâ”€â”€ phobert_model.py    # Class PhoBERTClassifier (PyTorch)
â”‚   â”‚   â””â”€â”€ dataset.py          # PyTorch Dataset cho PhoBERT
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # HÃ m tiá»‡n Ã­ch dÃ¹ng chung
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ metrics.py          # Accuracy, Precision, Recall, F1, Confusion Matrix
â”‚       â”œâ”€â”€ visualization.py    # Váº½ confusion matrix, ROC curve, loss/accuracy plots
â”‚       â”œâ”€â”€ config_loader.py    # Load YAML config
â”‚       â””â”€â”€ common.py           # set_seed(), save_model(), load_model()
â”‚
â”œâ”€â”€ scripts/                    # Scripts cháº¡y Ä‘á»™c láº­p (CLI)
â”‚   â”œâ”€â”€ train_ml.py             # Train 3 mÃ´ hÃ¬nh ML: python scripts/train_ml.py --model svm
â”‚   â”œâ”€â”€ train_dl.py             # Train PhoBERT: python scripts/train_dl.py --epochs 5
â”‚   â”œâ”€â”€ evaluate.py             # ÄÃ¡nh giÃ¡ táº¥t cáº£ mÃ´ hÃ¬nh trÃªn test set
â”‚   â””â”€â”€ predict.py              # Dá»± Ä‘oÃ¡n: python scripts/predict.py --text "Sáº£n pháº©m ráº¥t tá»‘t"
â”‚
â”œâ”€â”€ app/                        # Streamlit Web Application
â”‚   â”œâ”€â”€ app.py                  # Main Streamlit app (entry point)
â”‚   â”œâ”€â”€ pages/                  # Multi-page Streamlit app
â”‚   â”‚   â”œâ”€â”€ 1_Analyze.py     # Trang phÃ¢n tÃ­ch vÄƒn báº£n Ä‘Æ¡n láº»
â”‚   â”‚   â”œâ”€â”€ 2_Batch.py       # Upload file CSV Ä‘á»ƒ phÃ¢n tÃ­ch hÃ ng loáº¡t
â”‚   â”‚   â””â”€â”€ 3_Dashboard.py   # Dashboard thá»‘ng kÃª & visualization
â”‚   â”œâ”€â”€ components/             # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ model_selector.py  # Component chá»n model (NB/LR/SVM/PhoBERT)
â”‚   â”‚   â”œâ”€â”€ text_input.py      # Component nháº­p text vá»›i preprocessing preview
â”‚   â”‚   â””â”€â”€ result_display.py  # Component hiá»ƒn thá»‹ káº¿t quáº£ (sentiment + confidence)
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ inference.py        # Load models & predict
â”‚       â”œâ”€â”€ preprocessing.py    # Wrapper cho src.preprocessing
â”‚       â””â”€â”€ visualization.py    # Váº½ charts cho Streamlit
â”‚
â””â”€â”€ tests/                      # Unit Tests (pytest)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_preprocessing.py   # Test clean_text(), tokenize()
    â”œâ”€â”€ test_models.py          # Test model training/prediction
    â””â”€â”€ test_api.py             # Test API endpoints
```

---

## Workflow Thá»±c Thi

### 1ï¸âƒ£ Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
```bash
python scripts/preprocess_data.py --input data/raw/VLSP.xml --output data/processed/
```

### 2ï¸âƒ£ Huáº¥n luyá»‡n mÃ´ hÃ¬nh
```bash
# ML Models
python scripts/train_ml.py --model naive_bayes --config config/ml/a.yaml

# Deep Learning
python scripts/train_dl.py --config config/dl/UNGTHU.yaml --gpu 0
```

### 3ï¸âƒ£ ÄÃ¡nh giÃ¡
```bash
python scripts/evaluate.py --test-data data/processed/test.csv
```

### 4ï¸âƒ£ Dá»± Ä‘oÃ¡n
```bash
python scripts/predict.py --text "MÃ³n Äƒn ráº¥t ngon, tÃ´i sáº½ quay láº¡i"
```

### 5ï¸âƒ£ Cháº¡y Streamlit App

```bash
streamlit run app/app.py
# Má»Ÿ browser táº¡i: http://localhost:8501
```

---

## ğŸ³ Docker Deployment

```bash
# Build image
docker build -t sentiment-analysis:latest .

# Cháº¡y container
docker run -p 8501:8501 sentiment-analysis
```

---

## ğŸ“ Notes Quan Trá»ng

1. **KHÃ”NG commit** thÆ° má»¥c `data/`, `models/` lÃªn Git â†’ DÃ¹ng DVC hoáº·c Google Drive
2. **LÆ°u vectorizer** cÃ¹ng vá»›i ML models (TF-IDF pháº£i Ä‘Æ°á»£c fit trÃªn táº­p train)
3. **Seed cá»‘ Ä‘á»‹nh** trong `config.yaml` Ä‘á»ƒ reproducible
4. **Requirements.txt** nÃªn pin version: `torch==2.0.1` thay vÃ¬ `torch`
5. **Logging** káº¿t quáº£ huáº¥n luyá»‡n vÃ o file hoáº·c MLflow/WandB
