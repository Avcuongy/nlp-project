{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ea20f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Read file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4558641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/processed/train.csv\", encoding=\"utf-8\")\n",
    "df_val = pd.read_csv(\"../data/processed/val.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673e4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174874b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f538b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb7bf3",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cbf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_labels_train = df_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_labels_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of labels: {len(matrix_labels_train.unique())}\")\n",
    "print(f\"Labels: {matrix_labels_train.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d4b5e",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87746b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_labels_val = df_val[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_labels_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of labels: {len(matrix_labels_val.unique())}\")\n",
    "print(f\"Labels: {matrix_labels_val.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef342371",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Train, val split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6487d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train = df_train[[\"comment\"]]\n",
    "y_train = matrix_labels_train\n",
    "\n",
    "# Validation\n",
    "X_val = df_val[[\"comment\"]]\n",
    "y_val = matrix_labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1458716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le= LabelEncoder()\n",
    "y_train = le.fit_transform(y_train).astype(np.int64)\n",
    "y_val = le.transform(y_val).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eeee9a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Vectorize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16043c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    min_df=3,\n",
    "    max_df=0.95,\n",
    "    ngram_range=(3, 5),\n",
    "    max_features=30000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ade5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit TF-IDF on training and transform train/test\n",
    "X_train_vec = vec.fit_transform(X_train[\"comment\"])\n",
    "X_val_vec = vec.transform(X_val[\"comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c181003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To dense arrays\n",
    "X_train_vec = X_train_vec.toarray().astype(np.float32)\n",
    "X_val_vec = X_val_vec.toarray().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train shape: {X_train_vec.shape}\")\n",
    "print(f\"Test shape: {X_val_vec.shape}\")\n",
    "print(f\"Vocabulary size: {len(vec.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of classes (train): \", len(le.classes_))\n",
    "print(\"Number of classes (val): \", len(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train_vec.shape[1]\n",
    "n_classes = len(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8c950",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# FNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0266137",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcc52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model function\n",
    "def build_model(input_dim, output_dim, params):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(Dense(\n",
    "        params[\"hidden1\"], \n",
    "        activation=\"relu\", \n",
    "        input_shape=(input_dim,),\n",
    "        kernel_regularizer=l2(params.get(\"l2_reg\", 0.01))\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params[\"dropout1\"]))\n",
    "\n",
    "    # Second hidden layer\n",
    "    if params[\"n_layers\"] >= 2:\n",
    "        model.add(Dense(\n",
    "            params[\"hidden2\"], \n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=l2(params.get(\"l2_reg\", 0.01))\n",
    "        ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(params[\"dropout2\"]))\n",
    "\n",
    "    # Third hidden layer\n",
    "    if params[\"n_layers\"] >= 3:\n",
    "        model.add(Dense(\n",
    "            params[\"hidden3\"], \n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=l2(params.get(\"l2_reg\", 0.01))\n",
    "        ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(params[\"dropout3\"]))\n",
    "\n",
    "    # Fourth hidden layer\n",
    "    if params[\"n_layers\"] >= 4:\n",
    "        model.add(Dense(\n",
    "            params[\"hidden4\"], \n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=l2(params.get(\"l2_reg\", 0.01))\n",
    "        ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(params[\"dropout4\"]))\n",
    "\n",
    "    # Single-label multiclass: softmax + sparse categorical crossentropy\n",
    "    model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=params[\"lr\"]),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a896740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"n_layers\": trial.suggest_int(\"n_layers\", 2, 4),\n",
    "        \"hidden1\": trial.suggest_categorical(\"hidden1\", [512, 768, 1024]),\n",
    "        \"hidden2\": trial.suggest_categorical(\"hidden2\", [256, 384, 512]),\n",
    "        \"hidden3\": trial.suggest_categorical(\"hidden3\", [128, 192, 256]),\n",
    "        \"hidden4\": trial.suggest_categorical(\"hidden4\", [64, 96, 128]),\n",
    "        \"dropout1\": trial.suggest_float(\"dropout1\", 0.3, 0.6),\n",
    "        \"dropout2\": trial.suggest_float(\"dropout2\", 0.3, 0.5),\n",
    "        \"dropout3\": trial.suggest_float(\"dropout3\", 0.2, 0.5),\n",
    "        \"dropout4\": trial.suggest_float(\"dropout4\", 0.2, 0.4),\n",
    "        \"l2_reg\": trial.suggest_float(\"l2_reg\", 1e-5, 1e-2, log=True),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64]),\n",
    "    }\n",
    "\n",
    "    model = build_model(input_dim=n_features, output_dim=n_classes, params=params)\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Use precomputed numeric vectors for training/validation\n",
    "    model.fit(\n",
    "        X_train_vec,\n",
    "        y_train,\n",
    "        validation_data=(X_val_vec, y_val),\n",
    "        epochs=20,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    y_val_prob = model.predict(X_val_vec)\n",
    "    y_val_pred = np.argmax(y_val_prob, axis=1)\n",
    "\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e366f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best f1-macro:\", study.best_value)\n",
    "print(\"Best trial:\", study.best_trial.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f77481",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "print(\"Best params:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f944f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model with best hyperparameters\n",
    "model = build_model(n_features, n_classes, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc26ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final model\n",
    "model.fit(\n",
    "    X_train_vec, y_train, epochs=20, batch_size=best_params[\"batch_size\"], verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd194dfa",
   "metadata": {},
   "source": [
    "## Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57617864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_prob = model.predict(X_val_vec)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "metrics = {\n",
    "    \"accuracy_score\": accuracy_score(y_val, y_pred),\n",
    "    \"precision_macro\": precision_score(y_val, y_pred, average=\"macro\", zero_division=0),\n",
    "    \"recall_macro\": recall_score(y_val, y_pred, average=\"macro\", zero_division=0),\n",
    "    \"f1_macro\": f1_score(y_val, y_pred, average=\"macro\", zero_division=0),\n",
    "}\n",
    "\n",
    "matrix_metrics = pd.DataFrame.from_dict(metrics, orient=\"index\", columns=[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_metrics.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6978d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred, target_names=le.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0080a95",
   "metadata": {},
   "source": [
    "## Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c014435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/raw/val.csv\")\n",
    "df_test = df_test.iloc[-6:-1,:]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try prediction on some samples\n",
    "samples = df_test[\"comment\"].tolist()\n",
    "samples_vec = vec.transform(samples).toarray()\n",
    "\n",
    "# Use the trained final model for predictions\n",
    "probs = model.predict(samples_vec)\n",
    "preds = np.argmax(probs, axis=1)\n",
    "\n",
    "for i, (text, pred_idx) in enumerate(zip(samples, preds)):\n",
    "    label_name = le.inverse_transform([pred_idx])[0]\n",
    "    confidence = probs[i][pred_idx]\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"\\tText: {text}\")\n",
    "    print(f\"\\tPredicted label: {label_name}\")\n",
    "    print(f\"\\tConfidence: {confidence:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
